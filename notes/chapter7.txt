
第七章 调度（Scheduling）

本章讲述操作系统中的处理器调度策略，包括设计调度策略时需要考虑的各种权衡因素，以及如何在不同的计算场景中选择合适的策略。

----------------------------------------
📌 基本术语与性能指标

- Task（任务）：用户请求，可能是绘制鼠标、加载网页等。一个线程/进程可以包含多个任务。
- Response time（响应时间）：用户感知完成任务所需的时间。
- Predictability（可预测性）：响应时间的一致性，低方差代表高可预测性。
- Throughput（吞吐量）：单位时间完成任务的数量。
- Scheduling overhead（调度开销）：切换任务所需的时间。
- Fairness（公平性）：各任务获得资源的均衡性。
- Starvation（饥饿）：低优先级任务长时间无法获取资源的问题。

----------------------------------------
📚 7.1 单处理器调度（Uniprocessor Scheduling）

🎯 目标
- 提升响应时间、吞吐量，降低饥饿现象。

🎲 经典调度策略

1. FIFO（First-In-First-Out）
   - 按照到达顺序处理任务。
   - 简单但可能导致长任务阻塞短任务（Convoy effect）。

2. Round Robin（时间片轮转）
   - 每个任务获得一个固定时间片。
   - 提高响应时间，但时间片过小会导致上下文切换频繁。

3. SJF（Shortest Job First）
   - 优先处理估计运行时间最短的任务。
   - 可最小化平均响应时间，但易导致长任务饥饿。

4. MLFQ（多级反馈队列）
   - 多个优先级队列，任务可根据行为“升级”或“降级”。
   - 动态调整，有利于兼顾响应时间与吞吐量。
   - 挑战：如何避免滥用机制、如何估计任务类型。

5. Lottery Scheduling
   - 每个任务持有“票数”，随机抽票决定下一个任务。
   - 灵活实现比例分配（proportional-share scheduling）。

----------------------------------------
🧠 7.2 多处理器调度（Multiprocessor Scheduling）

📌 类型

- Global Queue（全局队列）
  - 所有 CPU 从同一个任务队列中取任务。
  - 易于负载均衡，但会出现缓存失效。

- Per-CPU Queue（每处理器队列）
  - 每个 CPU 有自己的任务队列。
  - 提高缓存命中率，但可能不平衡。

⚙️ 负载均衡策略

- Work Stealing（工作窃取）
  - 空闲 CPU 主动从其他繁忙 CPU 的队列中“偷”任务。
- Work Sharing
  - 繁忙 CPU 主动将任务“分享”出去。

----------------------------------------
🔋 7.3 能源感知调度（Energy-Aware Scheduling）

- 背景：现代 CPU 支持动态调频（DVFS）以节省能耗。
- 挑战：降低功耗的同时保证响应时间。
- 策略：
  - 合并任务到少数 CPU，关闭其他 CPU。
  - 动态调整 CPU 频率。
- 设计原则：应对突发负载、避免过度延迟。

----------------------------------------
⏱️ 7.4 实时调度（Real-Time Scheduling）

📌 特点

- 对时间要求严格，任务必须在截止时间前完成。
- 常用于嵌入式系统、音视频播放、控制系统等。

🎯 策略分类

1. 硬实时（Hard Real-Time）
   - 任务若未完成即为系统失败。

2. 软实时（Soft Real-Time）
   - 超时不会造成严重后果，但仍需尽量避免。

📈 常用策略

- RMS（Rate Monotonic Scheduling）：静态优先级，周期越短优先级越高。
- EDF（Earliest Deadline First）：动态优先级，截止时间最早的任务优先。

----------------------------------------
📊 7.5 排队理论基础（Queueing Theory）

🔍 定义

- 分析系统中任务到达、服务、完成的动态过程。

⏳ Little’s Law

  L = λ × W

- L：系统中平均任务数量。
- λ：任务平均到达速率。
- W：平均等待时间。

🎯 应用

- 分析调度策略对延迟与吞吐的影响。
- 预测不同负载下的表现。
- 优化任务队列大小与服务器数量。

----------------------------------------
💡 总结

- 调度策略是多目标优化问题，涉及响应时间、吞吐、公平性、开销等。
- 没有万能策略，应依据场景做权衡。
- 本章提供分析工具与思维框架，帮助设计高效调度器。


操作系统调度算法练习题答案

1. 在最短作业优先(SJF)调度中，如果调度器已经将任务分配给处理器，且在此期间没有其他任务变得可调度，调度器永远不会抢占当前任务。这是因为SJF是基于任务长度进行调度的，一旦任务开始执行，如果没有新的更短任务到达，就没有理由进行抢占。SJF只有在新的更短任务到达时才会考虑抢占。

2. FIFO（先进先出）在以下工作负载下表现最差：当一个非常长的任务先到达，而许多短任务随后到达时。例如：
   任务A：长度100，时间0到达
   任务B：长度1，时间1到达
   任务C：长度1，时间2到达
   任务D：长度1，时间3到达
   在这种情况下，平均响应时间将非常高，因为所有短任务都必须等待长任务完成。

3. 如果总是按SJF顺序完成作业，可能出现的问题：
   - 困难且重要的任务可能会被无限期推迟（饥饿问题）
   - 长期任务可能永远不会完成
   - 重要但耗时的任务可能会被忽视
   - 如果估计不准确，可能会做出错误的决策
   - 依赖性可能导致阻塞（例如，如果短任务依赖于长任务的完成）

4. 任务调度结果：

FIFO算法：
任务   长度   到达时间   完成时间   响应时间
0     85     0          85         85
1     30     10         115        105
2     35     15         150        135
3     20     80         170        90
4     50     85         220        135
平均响应时间：(85+105+135+90+135)/5 = 110

轮询(RR)算法（时间片10毫秒）：
任务0先运行10ms，然后任务1到达并运行10ms，然后任务2到达并运行10ms，之后三个任务轮流执行。
任务   长度   到达时间   完成时间   响应时间
0     85     0          210        210
1     30     10         140        130
2     35     15         165        150
3     20     80         190        110
4     50     85         220        135
平均响应时间：(210+130+150+110+135)/5 = 147

SJF算法：
任务   长度   到达时间   完成时间   响应时间
0     85     0          85         85（任务0首先运行完）
3     20     80         105        25（任务3在时间80到达并最短）
1     30     10         135        125（接下来是任务1）
2     35     15         170        155（然后是任务2）
4     50     85         220        135（最后是任务4）
平均响应时间：(85+125+155+25+135)/5 = 105

5. 是的，应用程序使用10个处理器可能比使用8个处理器运行得更慢。原因包括：
   - 并行开销：管理更多线程需要更多协调和同步开销
   - 缓存一致性问题：更多处理器导致缓存失效增加
   - 内存竞争：更多处理器共享相同的内存带宽
   - 调度和上下文切换成本增加
   - 应用程序可能不是完全并行的，Amdahl定律限制了可获得的加速

6. Round Robin(RR)与近似SJF的算法比较：
   - 当任务长度较短且差异不大时，RR会表现更好。因为10%的开销比1%的开销大得多，而且SJF的优势在短且同质的任务下不明显。
   - 当任务长度有显著差异，特别是当有很多短任务和少量长任务时，近似SJF的算法会表现更好。这是因为SJF可以显著降低平均响应时间，这种收益超过了额外9%的处理开销。
   - 在系统负载较低时，RR可能更好，因为开销差异更重要。
   - 在系统负载接近满负荷时，近似SJF算法可能更好，因为更优的调度决策带来的好处更明显。

7. 多级反馈队列(MLFQ)在以下非平凡工作负载下可以接近最优：
   - 混合了交互式任务和批处理任务的工作负载
   - 任务时间长短未知且变化很大的工作负载
   - I/O密集型和CPU密集型任务混合的情况
   
   然而，MLFQ不是严格意义上的最优策略，因为它不具备先验知识。对于任务长度已知的情况，SJF或SRPT通常是最优的。MLFQ通过学习任务行为来近似这些最优策略。

8. 使用Little定律，L = λW，其中L是系统中平均任务数，λ是到达率，W是平均响应时间。
   L = 5，λ = 1000任务/秒
   W = L/λ = 5/1000 = 0.005秒 = 5毫秒

9. 不可能同时具有有界平均响应时间和100%利用率。根据排队论，当系统利用率ρ接近1（100%）时，平均响应时间将按1/(1-ρ)增长，在ρ=1时变为无穷大。在实际系统中，100%利用率意味着系统无法处理任何突发负载，导致任务队列无限增长，响应时间无限增加。

10. 服务时间方差对系统响应时间有显著影响。高方差意味着服务时间变化大，会导致：
    - 阻塞效应增强：长任务会阻塞后面的短任务
    - 队列长度波动更大
    - 平均响应时间增加
    根据Pollaczek-Khinchin公式，对于M/G/1队列系统，平均响应时间为W = S(1 + ρC²/2(1-ρ))，其中C²是服务时间变异系数（方差除以均值的平方）。可以看出，服务时间方差越大，响应时间越长。

11. 轮询调度器的时间片大小：
    小时间片的优点：
    - 提高交互性和响应性
    - 减少单个长任务对系统的影响
    - 更公平地分配CPU时间
    
    小时间片的缺点：
    - 增加上下文切换开销
    - 降低CPU缓存效率
    - 可能导致CPU利用率下降
    - 对于计算密集型任务效率低

12. 多服务器场景下的队列设计：
    单一FIFO队列比每服务器一个队列提供更好的平均响应时间。原因：
    - 避免了"运气差"的问题（选到了处理慢的服务器或长任务的队列）
    - 负载自动均衡，不会出现一个服务器闲置而另一个服务器队列很长的情况
    - 减少了因服务时间变异导致的队列不平衡
    - 确保了公平性（先到先服务）
    
    这就是为什么现代银行、超市等通常采用单队列多服务器模式。

13. 三个任务（A、B、C）的完成时间：

a. FIFO：
   - 任务A：0-100ms，完成时间100ms
   - 任务B：100-320ms（10次循环，每次用CPU 2ms然后I/O 8ms，贯穿时间为10×20=200ms），完成时间320ms
   - 任务C：320-540ms（与B相同），完成时间540ms

b. 轮询（时间片1ms）：
   - A需要100个时间片
   - B和C各需要20个时间片（10次循环×2ms）
   - 模拟执行：A(1ms), B(1ms), C(1ms), A(1ms)...
   - 任务A：完成时间298ms（第100个时间片）
   - 任务B：完成时间318ms（B在A完成后很快完成）
   - 任务C：完成时间338ms（C在B完成后很快完成）

c. 轮询（时间片100ms）：
   - 任务A：0-100ms（用完一个时间片），完成时间100ms
   - 任务B：100-320ms（由于I/O操作，不需要被抢占），完成时间320ms
   - 任务C：320-540ms，完成时间540ms
   这种情况下结果与FIFO相同，因为A正好用完一个时间片，而B和C由于I/O不会被抢占。

d. 多级反馈队列（四个级别，最高优先级时间片1ms）：
   所有任务开始于最高优先级队列，时间片用完后降级。
   - 任务A：完成时间298ms（类似于1ms轮询）
   - 任务B：完成时间318ms
   - 任务C：完成时间338ms
   结果与1ms轮询类似，因为B和C由于I/O操作频繁回到高优先级队列。

e. 最短作业优先：
   - 任务B和C各需要20ms CPU时间，比A短
   - 任务B：0-220ms（包括I/O时间），完成时间220ms
   - 任务C：0-220ms（与B并行运行），完成时间220ms
   - 任务A：220-320ms，完成时间320ms

14. 不同调度策略的最优和最差工作负载：

a. FIFO：
   最优：当任务按照最短到最长顺序到达时，与SJF表现相同。
   最差：当任务按照最长到最短顺序到达时，与LJF表现相同。

b. 轮询：
   最优：当所有任务长度相同时，轮询与SJF表现相同。
   最差：没有明确的最差情况，但在短任务和长任务混合且短任务先到达的情况下，轮询会表现较差。

c. 多级反馈队列：
   最优：当系统能够准确预测任务长度时（通过学习），可以接近SJF。
   最差：当任务行为与MLFQ假设相反时（如短暂运行后变成长任务），可能接近LJF。

15. 比较可能导致饥饿的调度策略的实验设计：
    - 使用具有代表性的工作负载，包括不同长度的任务
    - 测量不仅平均响应时间，还要测量方差、最大响应时间和公平性指标
    - 设定时间上限，评估在此时间内完成的任务比例
    - 创建合成工作负载以测试极端情况
    - 使用不同的到达模式（均匀、突发等）
    - 评估不同类型任务的性能（短、中、长）
    - 实施防饥饿机制（如老化）并测量其影响
    - 在相同硬件和系统条件下进行比较

16. 社交网络用户优先级系统设计：

a. 固定优先级抢占式方案不适合，因为：
   - 可能导致低优先级用户（3级）完全饥饿
   - 违反了"所有用户仍将获得一些进展"的要求
   - 缺乏适应性，无法动态调整资源分配

b. UNIX风格的多级反馈队列适合，因为：
   - 提供优先级区分，高优先级用户获得更好响应时间
   - 通过降级机制防止饥饿，确保低优先级用户也能获得进展
   - 可以根据用户行为动态调整优先级
   - 可以配置参数（如时间片大小、降级速率）以符合需求
   - 可以实现优先级提升机制防止长时间等待

17. 动态优先级调度算法：

a. P0 = 0 且 b > a > 0：
   这产生了一种偏向CPU密集型任务的调度算法。运行中的任务优先级增长速度大于等待任务，使得长时间运行的任务能保持高优先级。这类似于"最长剩余时间优先"。

b. P0 = 0 且 a < b < 0：
   这产生了一种偏向I/O密集型任务的调度算法。当任务运行时，优先级下降得比等待时更快，鼓励短暂运行后让出CPU。这类似于多级反馈队列。

c. P0 = 0，a > 0 > b，抢占任务保持优先级：
   如果两个任务几乎同时到达，第一个任务开始运行，其优先级开始下降(b<0)。第二个任务在等待时优先级上升(a>0)，很快会抢占第一个任务。然后第二个任务优先级下降，第一个任务优先级上升，导致再次抢占。这会造成两个任务之间的频繁切换，产生"乒乓效应"。

d. 解决方法：
   - 引入最小运行时间保证，防止过早抢占
   - 抢占后降低新任务的初始优先级
   - 引入优先级阈值，只有当优先级差异超过阈值才抢占
   - 在计算优先级时考虑任务之前的等待和运行历史

18. 双核超线程计算机（2核×2线程=4逻辑处理器）的性能图：
    - 单任务运行：100%性能
    - 2个任务并行（1个额外任务）：每个约70-80%性能，总体吞吐量约140-160%
    - 3个任务并行（2个额外任务）：每个约50-60%性能，总体吞吐量约150-180%
    - 4个任务并行（3个额外任务）：每个约40-50%性能，总体吞吐量约160-200%
    - 5个任务并行（4个额外任务）：每个约20-25%性能，总体吞吐量与4个任务相似

19. 实现测试的方法：
    - 编写一个CPU密集型程序（如计算质数或矩阵乘法）
    - 运行不同数量的实例（1-5个）
    - 测量每个实例完成的工作量和总吞吐量
    - 比较结果与理论预测
    - 可以使用工具如nice、taskset控制进程的CPU亲和性
    - 使用系统监视器验证CPU使用情况

20. 针对不同调度策略的反制策略：

a. 后进先出(LIFO)：
   - 将应用分解为多个小任务，并按顺序提交
   - 每当发现队列中有其他任务时，取消当前任务并重新提交
   - 监控系统负载，在低谷期提交任务

b. 轮询(RR)：
   - 将任务分解为多个短任务，以减少每个任务的等待时间
   - 在每个时间片结束前主动放弃CPU（通过I/O或让步操作）
   - 利用多线程增加在就绪队列中的存在
   - 注：RR相对公平，很难显著提高响应时间

c. 多级反馈队列：
   - 将长任务分解为多个短任务
   - 在每个时间片结束前主动进行I/O操作，保持在高优先级队列
   - 创建"礼让模式"，定期让出CPU以回到高优先级队列
   - 操纵I/O模式以符合交互式任务特征

21. 系统资源利用率变化的影响：

a. 获取更快的CPU：
   可能会显著降低处理器利用率。因为系统明显是I/O受限（磁盘利用率99.7%），更快的CPU会使处理器更快完成任务并等待I/O，导致更多CPU空闲时间。

b. 获取更快的磁盘：
   很可能会显著增加处理器利用率。当前系统的瓶颈是磁盘（99.7%利用率），更快的磁盘会减少CPU等待I/O的时间，使处理器能够处理更多工作。

c. 增加多道程序设计程度：
   可能会略微增加处理器利用率。更多并发任务可能会更好地利用CPU在等待I/O期间的空闲时间，但由于系统已经I/O受限，提升有限。

d. 获取更快的网络：
   几乎不会影响处理器利用率。网络利用率只有5%，不是系统瓶颈，提升网络速度不会显著改变处理器等待I/O的时间。